[2025-04-22T03:36:01.415-0400] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-22T03:36:01.421-0400] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fashion_data_pipeline.execute_notebook manual__2025-04-22T07:35:08.767455+00:00 [queued]>
[2025-04-22T03:36:01.425-0400] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fashion_data_pipeline.execute_notebook manual__2025-04-22T07:35:08.767455+00:00 [queued]>
[2025-04-22T03:36:01.426-0400] {taskinstance.py:2867} INFO - Starting attempt 1 of 3
[2025-04-22T03:36:01.434-0400] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): execute_notebook> on 2025-04-22 07:35:08.767455+00:00
[2025-04-22T03:36:01.437-0400] {standard_task_runner.py:72} INFO - Started process 14894 to run task
[2025-04-22T03:36:01.440-0400] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'fashion_data_pipeline', 'execute_notebook', 'manual__2025-04-22T07:35:08.767455+00:00', '--job-id', '44', '--raw', '--subdir', 'DAGS_FOLDER/FashionData_DAG.py', '--cfg-path', '/tmp/tmpcqq1z8ws']
[2025-04-22T03:36:01.441-0400] {standard_task_runner.py:105} INFO - Job 44: Subtask execute_notebook
[2025-04-22T03:36:01.471-0400] {task_command.py:467} INFO - Running <TaskInstance: fashion_data_pipeline.execute_notebook manual__2025-04-22T07:35:08.767455+00:00 [running]> on host BOOK-KTS1KMKSNJ.
[2025-04-22T03:36:01.512-0400] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='fashion_data_pipeline' AIRFLOW_CTX_TASK_ID='execute_notebook' AIRFLOW_CTX_EXECUTION_DATE='2025-04-22T07:35:08.767455+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-04-22T07:35:08.767455+00:00'
[2025-04-22T03:36:01.513-0400] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-22T03:36:01.513-0400] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-22T03:36:01.513-0400] {logging_mixin.py:190} INFO - Current task name:execute_notebook state:running start_date:2025-04-22 07:36:01.422648+00:00
[2025-04-22T03:36:01.513-0400] {logging_mixin.py:190} INFO - Dag name:fashion_data_pipeline and current dag run status:running
[2025-04-22T03:36:01.514-0400] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-22T03:36:01.514-0400] {FashionData_DAG.py:58} INFO - Executing notebook: /home/megin_mathew/airflow/notebooks/Fashion_Data_Pipeline.ipynb
[2025-04-22T03:36:01.514-0400] {FashionData_DAG.py:59} INFO - Output will be saved to: /home/megin_mathew/airflow/notebook_outputs/Fashion_Data_Pipeline-output-2025-04-22.ipynb
[2025-04-22T03:36:01.514-0400] {FashionData_DAG.py:60} INFO - Parameters passed to notebook: {'execution_date': '2025-04-22T07:35:08.767455+00:00', 'dag_run_id': 'manual__2025-04-22T07:35:08.767455+00:00', 'ds': '2025-04-22', 'ds_nodash': '20250422'}
[2025-04-22T03:36:01.515-0400] {execute.py:83} INFO - Input Notebook:  /home/megin_mathew/airflow/notebooks/Fashion_Data_Pipeline.ipynb
[2025-04-22T03:36:01.515-0400] {execute.py:84} INFO - Output Notebook: /home/megin_mathew/airflow/notebook_outputs/Fashion_Data_Pipeline-output-2025-04-22.ipynb
[2025-04-22T03:36:02.460-0400] {clientwrap.py:44} INFO - Executing notebook with kernel: python3
[2025-04-22T03:36:02.461-0400] {engines.py:223} INFO - Executing Cell 1---------------------------------------
[2025-04-22T03:36:02.469-0400] {engines.py:261} INFO - Ending Cell 1------------------------------------------
[2025-04-22T03:36:02.471-0400] {engines.py:223} INFO - Executing Cell 2---------------------------------------
[2025-04-22T03:36:02.477-0400] {engines.py:261} INFO - Ending Cell 2------------------------------------------
[2025-04-22T03:36:02.479-0400] {engines.py:223} INFO - Executing Cell 3---------------------------------------
[2025-04-22T03:36:02.947-0400] {clientwrap.py:91} INFO - Requirement already satisfied: kagglehub in ./airflow_venv/lib/python3.12/site-packages (0.3.11)

[2025-04-22T03:36:02.997-0400] {clientwrap.py:91} INFO - Requirement already satisfied: pandas in ./airflow_venv/lib/python3.12/site-packages (2.2.3)
Requirement already satisfied: psycopg2-binary in ./airflow_venv/lib/python3.12/site-packages (2.9.10)
Requirement already satisfied: sqlalchemy in ./airflow_venv/lib/python3.12/site-packages (1.4.54)
Requirement already satisfied: packaging in ./airflow_venv/lib/python3.12/site-packages (from kagglehub) (24.2)
Requirement already satisfied: pyyaml in ./airflow_venv/lib/python3.12/site-packages (from kagglehub) (6.0.2)
Requirement already satisfied: requests in ./airflow_venv/lib/python3.12/site-packages (from kagglehub) (2.32.3)
Requirement already satisfied: tqdm in ./airflow_venv/lib/python3.12/site-packages (from kagglehub) (4.67.1)
Requirement already satisfied: numpy>=1.26.0 in ./airflow_venv/lib/python3.12/site-packages (from pandas) (2.2.5)
Requirement already satisfied: python-dateutil>=2.8.2 in ./airflow_venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in ./airflow_venv/lib/python3.12/site-packages (from pandas) (2025.2)
Requirement already satisfied: tzdata>=2022.7 in ./airflow_venv/lib/python3.12/site-packages (from pandas) (2025.2)
Requirement already satisfied: greenlet!=0.4.17 in ./airflow_venv/lib/python3.12/site-packages (from sqlalchemy) (3.2.0)
Requirement already satisfied: six>=1.5 in ./airflow_venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)
Requirement already satisfied: charset-normalizer<4,>=2 in ./airflow_venv/lib/python3.12/site-packages (from requests->kagglehub) (3.4.1)
Requirement already satisfied: idna<4,>=2.5 in ./airflow_venv/lib/python3.12/site-packages (from requests->kagglehub) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in ./airflow_venv/lib/python3.12/site-packages (from requests->kagglehub) (2.4.0)
Requirement already satisfied: certifi>=2017.4.17 in ./airflow_venv/lib/python3.12/site-packages (from requests->kagglehub) (2025.1.31)

[2025-04-22T03:36:03.420-0400] {engines.py:261} INFO - Ending Cell 3------------------------------------------
[2025-04-22T03:36:03.422-0400] {engines.py:223} INFO - Executing Cell 4---------------------------------------
[2025-04-22T03:36:03.506-0400] {clientwrap.py:91} INFO - ['KaggleDatasetAdapter', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', 'auth', 'cache', 'clients', 'colab_cache_resolver', 'competition', 'competition_download', 'config', 'dataset_download', 'dataset_load', 'dataset_upload', 'datasets', 'datasets_enums', 'datasets_helpers', 'env', 'exceptions', 'gcs_upload', 'get_package_asset_path', 'handle', 'http_resolver', 'integrity', 'kaggle_cache_resolver', 'kagglehub', 'load_dataset', 'logger', 'login', 'model_download', 'model_upload', 'models', 'models_helpers', 'notebook_output_download', 'notebooks', 'package_import', 'packages', 'registry', 'resolver', 'signing', 'tracker', 'utility_script_install', 'utility_scripts', 'whoami']

[2025-04-22T03:36:03.507-0400] {clientwrap.py:98} WARNING - /home/megin_mathew/airflow_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm

[2025-04-22T03:36:03.508-0400] {engines.py:261} INFO - Ending Cell 4------------------------------------------
[2025-04-22T03:36:03.510-0400] {engines.py:223} INFO - Executing Cell 5---------------------------------------
[2025-04-22T03:36:04.081-0400] {clientwrap.py:91} INFO - Requirement already satisfied: kaggle in ./airflow_venv/lib/python3.12/site-packages (1.7.4.2)
Requirement already satisfied: bleach in ./airflow_venv/lib/python3.12/site-packages (from kaggle) (6.2.0)

[2025-04-22T03:36:04.133-0400] {clientwrap.py:91} INFO - Requirement already satisfied: certifi>=14.05.14 in ./airflow_venv/lib/python3.12/site-packages (from kaggle) (2025.1.31)
Requirement already satisfied: charset-normalizer in ./airflow_venv/lib/python3.12/site-packages (from kaggle) (3.4.1)
Requirement already satisfied: idna in ./airflow_venv/lib/python3.12/site-packages (from kaggle) (3.10)
Requirement already satisfied: protobuf in ./airflow_venv/lib/python3.12/site-packages (from kaggle) (5.29.4)
Requirement already satisfied: python-dateutil>=2.5.3 in ./airflow_venv/lib/python3.12/site-packages (from kaggle) (2.9.0.post0)
Requirement already satisfied: python-slugify in ./airflow_venv/lib/python3.12/site-packages (from kaggle) (8.0.4)
Requirement already satisfied: requests in ./airflow_venv/lib/python3.12/site-packages (from kaggle) (2.32.3)
Requirement already satisfied: setuptools>=21.0.0 in ./airflow_venv/lib/python3.12/site-packages (from kaggle) (79.0.0)
Requirement already satisfied: six>=1.10 in ./airflow_venv/lib/python3.12/site-packages (from kaggle) (1.17.0)
Requirement already satisfied: text-unidecode in ./airflow_venv/lib/python3.12/site-packages (from kaggle) (1.3)
Requirement already satisfied: tqdm in ./airflow_venv/lib/python3.12/site-packages (from kaggle) (4.67.1)
Requirement already satisfied: urllib3>=1.15.1 in ./airflow_venv/lib/python3.12/site-packages (from kaggle) (2.4.0)
Requirement already satisfied: webencodings in ./airflow_venv/lib/python3.12/site-packages (from kaggle) (0.5.1)

[2025-04-22T03:36:04.698-0400] {clientwrap.py:91} INFO - Note: you may need to restart the kernel to use updated packages.

[2025-04-22T03:36:04.702-0400] {engines.py:261} INFO - Ending Cell 5------------------------------------------
[2025-04-22T03:36:04.704-0400] {engines.py:223} INFO - Executing Cell 6---------------------------------------
[2025-04-22T03:36:04.798-0400] {clientwrap.py:91} INFO - Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/megin_mathew/.config/kaggle/kaggle.json'

[2025-04-22T03:36:04.799-0400] {clientwrap.py:91} INFO - Kaggle module is successfully installed!

[2025-04-22T03:36:04.801-0400] {engines.py:261} INFO - Ending Cell 6------------------------------------------
[2025-04-22T03:36:04.803-0400] {engines.py:223} INFO - Executing Cell 7---------------------------------------
[2025-04-22T03:36:04.811-0400] {clientwrap.py:91} INFO - Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/megin_mathew/.config/kaggle/kaggle.json'
Kaggle API authentication successful!

[2025-04-22T03:36:04.813-0400] {engines.py:261} INFO - Ending Cell 7------------------------------------------
[2025-04-22T03:36:04.816-0400] {engines.py:223} INFO - Executing Cell 8---------------------------------------
[2025-04-22T03:36:58.194-0400] {clientwrap.py:91} INFO - Downloaded: transactions.csv → Stored in: C:/Users/megin/fashion_dataset

[2025-04-22T03:37:02.298-0400] {clientwrap.py:98} WARNING - /home/megin_mathew/airflow_venv/lib/python3.12/site-packages/kagglehub/pandas_datasets.py:91: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.
  result = read_function(

[2025-04-22T03:37:08.112-0400] {clientwrap.py:91} INFO - Downloaded: customers.csv → Stored in: C:/Users/megin/fashion_dataset

[2025-04-22T03:37:08.638-0400] {clientwrap.py:91} INFO - Downloaded: discounts.csv → Stored in: C:/Users/megin/fashion_dataset

[2025-04-22T03:37:08.952-0400] {clientwrap.py:91} INFO - Downloaded: employees.csv → Stored in: C:/Users/megin/fashion_dataset

[2025-04-22T03:37:09.526-0400] {clientwrap.py:91} INFO - Downloaded: products.csv → Stored in: C:/Users/megin/fashion_dataset

[2025-04-22T03:37:09.654-0400] {clientwrap.py:91} INFO - Downloaded: stores.csv → Stored in: C:/Users/megin/fashion_dataset

[2025-04-22T03:37:09.660-0400] {engines.py:261} INFO - Ending Cell 8------------------------------------------
[2025-04-22T03:37:09.667-0400] {engines.py:223} INFO - Executing Cell 9---------------------------------------
[2025-04-22T03:37:09.687-0400] {engines.py:261} INFO - Ending Cell 9------------------------------------------
[2025-04-22T03:37:09.691-0400] {engines.py:223} INFO - Executing Cell 10--------------------------------------
[2025-04-22T03:37:09.694-0400] {engines.py:261} INFO - Ending Cell 10-----------------------------------------
[2025-04-22T03:37:09.697-0400] {engines.py:223} INFO - Executing Cell 11--------------------------------------
[2025-04-22T03:37:11.836-0400] {clientwrap.py:98} WARNING - 25/04/22 03:37:11 WARN Utils: Your hostname, BOOK-KTS1KMKSNJ resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)
25/04/22 03:37:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address

[2025-04-22T03:37:12.135-0400] {clientwrap.py:98} WARNING - Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).

[2025-04-22T03:37:12.342-0400] {clientwrap.py:98} WARNING - 25/04/22 03:37:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/22 03:37:12 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).

[2025-04-22T03:37:12.813-0400] {clientwrap.py:98} WARNING - 25/04/22 03:37:12 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [D:/spark_temp]. Please check your configured local directories.

[2025-04-22T03:37:13.245-0400] {clientwrap.py:98} WARNING - 2025-04-22 03:37:13,242 - INFO - Starting data load process...

[2025-04-22T03:37:13.246-0400] {clientwrap.py:98} WARNING - 2025-04-22 03:37:13,243 - ERROR - Fatal error: Missing required environment variable: DB_USER
Traceback (most recent call last):
  File "/tmp/ipykernel_14896/3969976327.py", line 492, in <module>
    load_data_to_postgres()
  File "/tmp/ipykernel_14896/3969976327.py", line 412, in load_data_to_postgres
    raise ValueError(f"Missing required environment variable: {var_name}")
ValueError: Missing required environment variable: DB_USER

[2025-04-22T03:37:13.248-0400] {engines.py:261} INFO - Ending Cell 11-----------------------------------------
[2025-04-22T03:37:13.252-0400] {engines.py:223} INFO - Executing Cell 12--------------------------------------
[2025-04-22T03:37:13.254-0400] {engines.py:261} INFO - Ending Cell 12-----------------------------------------
[2025-04-22T03:37:15.896-0400] {FashionData_DAG.py:79} INFO - Notebook execution completed successfully
[2025-04-22T03:37:15.897-0400] {python.py:240} INFO - Done. Returned value was: True
[2025-04-22T03:37:15.969-0400] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-22T03:37:15.970-0400] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=fashion_data_pipeline, task_id=execute_notebook, run_id=manual__2025-04-22T07:35:08.767455+00:00, execution_date=20250422T073508, start_date=20250422T073601, end_date=20250422T073715
[2025-04-22T03:37:15.997-0400] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-22T03:37:15.997-0400] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-22T03:37:15.998-0400] {logging_mixin.py:190} INFO - Dag name:fashion_data_pipeline queued_at:2025-04-22 07:35:08.801358+00:00
[2025-04-22T03:37:15.998-0400] {logging_mixin.py:190} INFO - Task hostname:BOOK-KTS1KMKSNJ. operator:PythonOperator
[2025-04-22T03:37:16.055-0400] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-22T03:37:16.088-0400] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-04-22T03:37:16.088-0400] {local_task_job_runner.py:245} INFO - ::endgroup::
